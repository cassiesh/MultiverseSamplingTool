{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de879e06",
   "metadata": {},
   "source": [
    "### 0. Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0. Set Up Environment\n",
    "\n",
    "# This notebook is tested with Python 3.9.7. Follow the steps below to set up the environment:\n",
    "\n",
    "# 1. Create a virtual environment:\n",
    "!python -m venv venv\n",
    "\n",
    "# 2. Activate the virtual environment:\n",
    "# On Windows:\n",
    "!venv/Scripts/activate\n",
    "\n",
    "# 3. Install required packages from `requirements.txt`:\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 4. Select the correct kernel in Jupyter Notebook:\n",
    "# After activating the virtual environment, run the following command to add the environment as a Jupyter kernel:\n",
    "!python -m ipykernel install --user --name=venv --display-name \"Python (venv)\"\n",
    "\n",
    "# Then, in the Jupyter Notebook interface, select \"Python (venv)\" as the kernel for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a116182",
   "metadata": {},
   "source": [
    "### 1. Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcd099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "import openpyxl\n",
    "from pathlib import Path\n",
    "from scipy import io\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Import helper functions from your uploaded script\n",
    "from helper import (\n",
    "    OUTPUT_PATH,\n",
    "    objective_func_reg,\n",
    "    objective_func_reg_IVF,\n",
    "    initialize_bo,\n",
    "    run_bo,\n",
    "    average_nearest_neighbor_distance,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8d168",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d9b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data_path):\n",
    "    \"\"\"\n",
    "    Loads all necessary data files and prepares them for analysis.\n",
    "\n",
    "    Args:\n",
    "        data_path (Path): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - np.ndarray: The main feature data.\n",
    "            - np.ndarray: The 2D embedding of the feature space.\n",
    "            - np.ndarray: The target scores (e.g., extraversion) for all participants.\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    features_sp = io.loadmat(data_path / 'mats.mat')['mats']\n",
    "    embed_features = io.loadmat(data_path / 'tSNEembeddingFeatures5.mat')['tSNEembedding']\n",
    "    features_sp_dict = io.loadmat(data_path / 'LPP_sep.mat')['LPP_sep']\n",
    "    features_sp_df = pd.DataFrame(features_sp_dict, columns=['subject', 'emotion', 'path', 'LPP'])\n",
    "    subject_ls_str = features_sp_df['subject'].apply(lambda x: str(x)).unique()\n",
    "    subject_ls = [item.strip(\"['']\").strip() for item in subject_ls_str]\n",
    "    subject_df = pd.DataFrame(np.array(subject_ls, dtype=int), columns=['subj'])\n",
    "    scores = pd.read_csv(data_path / 'Extraversion.dat', sep=\"\\t\", skiprows=1,\n",
    "                         names=['subj', 'Extrav', 'NEOE_W', 'NEOE_G', 'NEOE_A', 'NEOE_AC', 'NEOE_ES', 'NEOE_PE'])\n",
    "    extrav_sc = pd.merge(subject_df, scores, on='subj')\n",
    "    y_scores = extrav_sc['Extrav'].values\n",
    "    print(\"Data loading complete.\")\n",
    "    return features_sp, embed_features, y_scores\n",
    "\n",
    "def create_pipeline_configurations():\n",
    "    \"\"\"\n",
    "    Creates a DataFrame of all possible pipeline configurations from predefined components.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: A DataFrame where each row is a unique pipeline configuration.\n",
    "            - dict: A dictionary version of the pipeline configurations for easy lookup.\n",
    "    \"\"\"\n",
    "    print(\"Creating pipeline configurations...\")\n",
    "    bl = ['b-200', 'b-100']\n",
    "    rf = ['rAvg', 'rMas', 'rCSD']\n",
    "    tw = ['500200', '500300', '600200', '600300', '600600', '700200', '700300', '700600', '450100', 'GAV400', 'SAV400']\n",
    "    el = ['CP1CP2PzP3P4', 'P3P4CP1CP2', 'P3PzP4', 'FzCzPz', 'CP1CP2', 'Cz', 'Pz', 'around']\n",
    "    config = {}\n",
    "    count = 0\n",
    "    for bl_temp in bl:\n",
    "        for rf_temp in rf:\n",
    "            for tw_temp in tw:\n",
    "                for el_temp in el:\n",
    "                    config.setdefault('bl_run', {})[count] = bl_temp\n",
    "                    config.setdefault('rf_run', {})[count] = rf_temp\n",
    "                    config.setdefault('tw_run', {})[count] = tw_temp\n",
    "                    config.setdefault('el_run', {})[count] = el_temp\n",
    "                    count += 1\n",
    "    pipelines_df = pd.DataFrame(config)\n",
    "    pipelines_df.to_csv(OUTPUT_PATH / \"Pipelines.csv\", index=False)\n",
    "    print(f\"{len(pipelines_df)} pipeline configurations created.\")\n",
    "    return pipelines_df, config\n",
    "\n",
    "def export_all_data_to_excel(num_items, data_dict):\n",
    "    \"\"\"\n",
    "    Exports all performance data from both datasets to a single Excel file with 8 sheets.\n",
    "\n",
    "    Args:\n",
    "        num_items (int): The sample size, used for file naming.\n",
    "        data_dict (dict): A dictionary containing the 8 DataFrames to export.\n",
    "    \"\"\"\n",
    "    output_filename = OUTPUT_PATH / f'All_Results_Combined_{num_items}.xlsx'\n",
    "    print(f\"\\nExporting all data to a single Excel file: {output_filename}\")\n",
    "\n",
    "    with pd.ExcelWriter(output_filename) as writer:\n",
    "        # Prediction Sheets\n",
    "        data_dict['All_Prediction'].to_excel(writer, sheet_name='All_Pipelines_Prediction', index=False)\n",
    "        data_dict['Stra_Prediction'].to_excel(writer, sheet_name='Stratified_Prediction', index=False)\n",
    "        data_dict['Rand_Prediction'].to_excel(writer, sheet_name='Random_Prediction', index=False)\n",
    "        data_dict['AL_Prediction'].to_excel(writer, sheet_name='AL_Prediction', index=False)\n",
    "        \n",
    "        # Lockbox Sheets\n",
    "        data_dict['All_Lockbox'].to_excel(writer, sheet_name='All_Pipelines_Lockbox', index=False)\n",
    "        data_dict['Stra_Lockbox'].to_excel(writer, sheet_name='Stratified_Lockbox', index=False)\n",
    "        data_dict['Rand_Lockbox'].to_excel(writer, sheet_name='Random_Lockbox', index=False)\n",
    "        data_dict['AL_Lockbox'].to_excel(writer, sheet_name='AL_Lockbox', index=False)\n",
    "    \n",
    "    print(\"Export complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e22605",
   "metadata": {},
   "source": [
    "### 3. Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03875743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exhaustive_analysis(dataset_name, feature_data, y_data, model_config):\n",
    "    \"\"\"\n",
    "    Runs the analysis for every pipeline to establish a ground truth for a given dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset (e.g., \"Prediction\", \"Lockbox\") for file naming.\n",
    "        feature_data (np.ndarray): The feature data for the dataset.\n",
    "        y_data (np.ndarray): The target scores for the dataset.\n",
    "        model_config (dict): The dictionary of all pipeline configurations.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of performance scores (R-squared) for every pipeline.\n",
    "    \"\"\"\n",
    "    print(f\"Starting exhaustive analysis for '{dataset_name}' dataset...\")\n",
    "    num_pipelines = len(model_config['bl_run'])\n",
    "    predicted_acc = np.zeros(num_pipelines)\n",
    "    for i in range(num_pipelines):\n",
    "        temp_pred_acc, _ = objective_func_reg(i, y_data, model_config, feature_data)\n",
    "        predicted_acc[i] = temp_pred_acc\n",
    "    filepath = OUTPUT_PATH / f\"PredictedAcc_Full_{dataset_name}.p\"\n",
    "    with open(filepath, \"wb\") as f: pickle.dump(predicted_acc, f)\n",
    "    print(f\"Exhaustive analysis for '{dataset_name}' complete. Results saved.\")\n",
    "    return predicted_acc\n",
    "\n",
    "def evaluate_pipelines(pipeline_indices, feature_data, y_data, model_config):\n",
    "    \"\"\"\n",
    "    Evaluates a pre-selected list of pipelines on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        pipeline_indices (list or np.ndarray): Indices of the pipelines to evaluate.\n",
    "        feature_data (np.ndarray): The feature data for the dataset.\n",
    "        y_data (np.ndarray): The target scores for the dataset.\n",
    "        model_config (dict): The dictionary of all pipeline configurations.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of performance scores for the evaluated pipelines.\n",
    "    \"\"\"\n",
    "    performance = np.zeros(len(pipeline_indices))\n",
    "    for idx, pipeline_idx in enumerate(pipeline_indices):\n",
    "        perf, _ = objective_func_reg(pipeline_idx, y_data, model_config, feature_data)\n",
    "        performance[idx] = perf\n",
    "    return performance\n",
    "\n",
    "def create_unique_balanced_stratified_sample(df, sample_size):\n",
    "    \"\"\"\n",
    "    Creates a single balanced, stratified sample without replacement.\n",
    "    \"\"\"\n",
    "    categories = [\"bl_run\", \"rf_run\", \"tw_run\", \"el_run\"]\n",
    "    selected_indices = []\n",
    "    remaining_size = sample_size\n",
    "\n",
    "    while remaining_size > 0 and len(selected_indices) < sample_size:\n",
    "        len_before = len(selected_indices)\n",
    "        for category in categories:\n",
    "            available_df = df.loc[~df.index.isin(selected_indices)]\n",
    "            if available_df.empty: continue\n",
    "            \n",
    "            category_groups = available_df.groupby(category)\n",
    "            if not category_groups: continue\n",
    "            \n",
    "            # Sample one from each group if possible\n",
    "            sampled = category_groups.apply(lambda x: x.sample(1)).index.get_level_values(1)\n",
    "            \n",
    "            # Add unique indices up to the remaining sample size\n",
    "            new_indices = [idx for idx in sampled if idx not in selected_indices]\n",
    "            num_to_add = min(remaining_size, len(new_indices))\n",
    "            selected_indices.extend(new_indices[:num_to_add])\n",
    "            remaining_size -= num_to_add\n",
    "            if remaining_size <= 0: break\n",
    "        \n",
    "        # Break if no new pipelines are added in a full loop\n",
    "        if len(selected_indices) == len_before:\n",
    "            break\n",
    "            \n",
    "    # If still not enough, fill randomly from remaining\n",
    "    if len(selected_indices) < sample_size:\n",
    "        remaining_indices = df.index[~df.index.isin(selected_indices)]\n",
    "        fill_count = sample_size - len(selected_indices)\n",
    "        if len(remaining_indices) >= fill_count:\n",
    "            selected_indices.extend(np.random.choice(remaining_indices, fill_count, replace=False))\n",
    "\n",
    "    return df.loc[selected_indices]\n",
    "\n",
    "def create_stratified_samples(df, sample_sizes):\n",
    "    \"\"\"\n",
    "    Creates multiple stratified samples of different sizes.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        f\"Sample_{size}\": create_unique_balanced_stratified_sample(df, size)\n",
    "        for size in sample_sizes\n",
    "    }\n",
    "\n",
    "def identify_best_pipelines(dataset_name, num_items, pipelines_df, full_perf, al_df, rand_df, stra_df):\n",
    "    \"\"\"\n",
    "    Identifies and saves the top N performing pipelines for each sampling method.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): The name of the dataset being analyzed (e.g., \"Prediction\", \"Lockbox\"),\n",
    "                            used for naming the output file.\n",
    "        num_items (int): The number of samples used in the sampling methods, for file naming.\n",
    "        pipelines_df (pd.DataFrame): The master DataFrame containing all possible pipeline\n",
    "                                     configurations (specs).\n",
    "        full_perf (np.ndarray): An array of performance scores for the full multiverse.\n",
    "        al_df (pd.DataFrame): A DataFrame containing the specs and performance of pipelines\n",
    "                              selected by Active Learning. Must include a 'perf_pipelines' column.\n",
    "        rand_df (pd.DataFrame): A DataFrame for pipelines from Random sampling, including 'perf_pipelines'.\n",
    "        stra_df (pd.DataFrame): A DataFrame for pipelines from Stratified sampling, including 'perf_pipelines'.\n",
    "    \"\"\"\n",
    "    print(f\"Identifying best pipelines for '{dataset_name}'...\")\n",
    "    N = 10\n",
    "    \n",
    "    # Helper function to format the output strings\n",
    "    def get_best_string(df):\n",
    "        sorted_df = df.sort_values(by='perf_pipelines', ascending=False).head(N)\n",
    "        # Separate specs from performance\n",
    "        specs = sorted_df.drop(columns=['perf_pipelines'])\n",
    "        perf = sorted_df['perf_pipelines']\n",
    "        # Create string\n",
    "        best_strings = specs.apply(lambda row: ', '.join(row.astype(str)), axis=1)\n",
    "        best_strings = best_strings + ', ' + perf.astype(str)\n",
    "        return best_strings.values\n",
    "\n",
    "    # For Full Sample\n",
    "    full_indices_sorted = np.argsort(full_perf)[-N:][::-1]\n",
    "    full_specs_sorted = pipelines_df.iloc[full_indices_sorted]\n",
    "    full_perf_sorted = full_perf[full_indices_sorted]\n",
    "    full_sample_best_series = full_specs_sorted.apply(lambda row: ', '.join(row.values.astype(str)), axis=1)\n",
    "    full_sample_best = (full_sample_best_series + ', ' + pd.Series(full_perf_sorted, index=full_sample_best_series.index).astype(str)).values\n",
    "\n",
    "    best_pipeline = pd.DataFrame({\n",
    "        'Best Full Sample': full_sample_best,\n",
    "        'Best Active Learning': get_best_string(al_df),\n",
    "        'Best Random Sampling': get_best_string(rand_df),\n",
    "        'Best Stratified Sampling': get_best_string(stra_df)\n",
    "    })\n",
    "    best_pipeline.to_csv(OUTPUT_PATH / f'bestPipelines_{dataset_name}_{num_items}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aefe81",
   "metadata": {},
   "source": [
    "### 4. Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963f8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raincloud(dataset_name, num_items, full_perf, al_estimated_perf, rand_df, stra_df, al_burnin_indices, al_intelligent_indices):\n",
    "    \"\"\"\n",
    "    Generates and saves a raincloud plot with special coloring for Active Learning.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): The name of the dataset for the plot title and filename.\n",
    "        num_items (int): The number of samples for the plot title.\n",
    "        full_perf (np.ndarray): An array of performance scores for the full multiverse.\n",
    "        al_estimated_perf (np.ndarray): The GP's estimated performance for ALL pipelines. This is\n",
    "                                        used for the Active Learning violin and box plot.\n",
    "        rand_df (pd.DataFrame): DataFrame for Random sampling, must contain a 'perf_pipelines' column.\n",
    "        stra_df (pd.DataFrame): DataFrame for Stratified sampling, must contain a 'perf_pipelines' column.\n",
    "        al_burnin_indices (list): A list of pipeline indices that were sampled by Active Learning\n",
    "                                  during the initial random \"burn-in\" phase.\n",
    "        al_intelligent_indices (list): A list of pipeline indices that were sampled by Active\n",
    "                                       Learning during the intelligent optimization phase.\n",
    "    \"\"\"\n",
    "    print(f\"Generating raincloud plot for '{dataset_name}'...\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    colors = ['blue','green', 'orange', 'red']\n",
    "    \n",
    "    data_to_plot = [full_perf, al_estimated_perf, stra_df['perf_pipelines'], rand_df['perf_pipelines']]\n",
    "    bp = ax.boxplot(data_to_plot, patch_artist=True, vert=False)\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.4)\n",
    "    \n",
    "    vp = ax.violinplot(data_to_plot, points=500, showmeans=False, showextrema=False, showmedians=False, vert=False)\n",
    "    for idx, b in enumerate(vp['bodies']):\n",
    "        b.get_paths()[0].vertices[:, 1] = np.clip(b.get_paths()[0].vertices[:, 1], idx + 1, idx + 2)\n",
    "        b.set_color(colors[idx])\n",
    "        \n",
    "    for idx, data in enumerate(data_to_plot):\n",
    "        y = np.full(len(data), idx + .8)\n",
    "        y = y.astype(float)\n",
    "        y += np.random.uniform(low=-.05, high=.05, size=len(y))\n",
    "        if idx == 1: # Active Learning\n",
    "            colors_dots = ['lightgreen'] * len(data)\n",
    "            for i in al_burnin_indices: colors_dots[i] = 'lightgreen'\n",
    "            for i in al_intelligent_indices: colors_dots[i] = 'darkgreen'\n",
    "            ax.scatter(data, y, s=10, c=colors_dots, alpha=0.6)\n",
    "        else:\n",
    "            ax.scatter(data, y, s=10, c=colors[idx])\n",
    "\n",
    "    plt.yticks(np.arange(1, 5, 1), ['Full Sample', 'Active learning', 'Stratified Sampling', 'Random Sampling'])\n",
    "    plt.xlabel('R-square')\n",
    "    plt.title(f\"R-square values of the sampled pipelines\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.2)\n",
    "    plt.savefig(OUTPUT_PATH / f'raincloud_plot_{dataset_name}_{num_items}samples.svg')\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_sampled_pipelines_in_space(dataset_name, num_items, embed_features, al_indices, rand_indices, stra_indices):\n",
    "    \"\"\"\n",
    "    Plots where the sampled pipelines fall in the 2D embedding space.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): The name of the dataset for the plot title and filename.\n",
    "        num_items (int): The number of samples for the plot title.\n",
    "        embed_features (np.ndarray): A 2D array of coordinates for ALL pipelines in the multiverse.\n",
    "        al_indices (np.ndarray): An array of indices for pipelines selected by Active Learning.\n",
    "        rand_indices (np.ndarray): An array of indices for pipelines selected by Random sampling.\n",
    "        stra_indices (np.ndarray): An array of indices for pipelines selected by Stratified sampling.\n",
    "    \"\"\"\n",
    "    print(f\"Plotting sampled pipelines in space for '{dataset_name}'...\")\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharex=True, sharey=True)\n",
    "    \n",
    "    axs[0].scatter(embed_features[:, 0], embed_features[:, 1], color='blue', label='Full Multiverse', alpha=0.1)\n",
    "    axs[0].scatter(embed_features[rand_indices, 0], embed_features[rand_indices, 1], color='red', label='Random Sampling')\n",
    "    axs[0].set_title('Random Sampling'); axs[0].legend(); axs[0].grid(True)\n",
    "\n",
    "    axs[1].scatter(embed_features[:, 0], embed_features[:, 1], color='blue', label='Full Multiverse', alpha=0.1)\n",
    "    axs[1].scatter(embed_features[stra_indices, 0], embed_features[stra_indices, 1], color='orange', label='Stratified Sampling')\n",
    "    axs[1].set_title('Stratified Sampling'); axs[1].legend(); axs[1].grid(True)\n",
    "\n",
    "    axs[2].scatter(embed_features[:, 0], embed_features[:, 1], color='blue', label='Full Multiverse', alpha=0.1)\n",
    "    axs[2].scatter(embed_features[al_indices, 0], embed_features[al_indices, 1], color='green', label='Active Learning')\n",
    "    axs[2].set_title('Active Learning'); axs[2].legend(); axs[2].grid(True)\n",
    "\n",
    "    fig.text(0.5, 0.04, 'Dimension 1', ha='center', va='center', fontsize=14)\n",
    "    fig.text(0.04, 0.5, 'Dimension 2', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "    plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n",
    "    plt.savefig(OUTPUT_PATH / f'samplePipelines_{dataset_name}_{num_items}samples.svg')\n",
    "    plt.close(fig)\n",
    "\n",
    "def spec_curve(spec_df, dataset_name, sampling_method, num_items, all_sampled_indices=None, burnin_indices=None):\n",
    "    \"\"\"\n",
    "    Generates and saves a specification curve plot. This version ensures correct alignment\n",
    "    between the performance plot and the decision node heatmap.\n",
    "\n",
    "    Args:\n",
    "        spec_df (pd.DataFrame): A DataFrame containing pipeline specifications and a 'perf_pipelines' column.\n",
    "                                For AL, this should contain all pipelines with estimated performance.\n",
    "                                For others, it contains only the sampled pipelines.\n",
    "        dataset_name (str): The name of the dataset for the plot title and filename.\n",
    "        sampling_method (str): The name of the sampling method (\"AL\", \"Rand\", \"Stra\").\n",
    "        num_items (int): The number of samples for the plot title.\n",
    "        all_sampled_indices (list, optional): All indices sampled by AL (burn-in + intelligent).\n",
    "                                              Required if sampling_method is 'AL'. Defaults to None.\n",
    "        burnin_indices (list, optional): Indices sampled by AL during the burn-in phase.\n",
    "                                         Required if sampling_method is 'AL'. Defaults to None.\n",
    "    \"\"\"\n",
    "    print(f\"Generating spec curve for {dataset_name} - {sampling_method}...\")\n",
    "\n",
    "    # 1. Sort the data ONCE by performance. This is the master order for the x-axis.\n",
    "    data_sorted = spec_df.sort_values(by='perf_pipelines', ascending=False).reset_index()\n",
    "    \n",
    "    # Extract sorted performance for the top plot\n",
    "    acc_sort = data_sorted['perf_pipelines']\n",
    "\n",
    "    # Extract the specification choices, also sorted\n",
    "    df_forks = data_sorted.drop(columns=['perf_pipelines', 'index']) # Drop original index if it exists\n",
    "    if 'indices' in df_forks.columns: df_forks = df_forks.drop(columns=['indices'], errors='ignore')\n",
    "\n",
    "    # 2. Create the list of all possible decision options for the y-axis, grouped by category.\n",
    "    decision_categories = ['bl_run', 'rf_run', 'tw_run', 'el_run']\n",
    "    items = []\n",
    "    for cat in decision_categories:\n",
    "        # Sort the unique values within each category for consistent plotting\n",
    "        unique_vals = sorted(spec_df[cat].unique().astype(str))\n",
    "        items.extend(unique_vals)\n",
    "    \n",
    "    # Create a mapping from each decision item to its y-position on the plot\n",
    "    item_y_map = {item: i for i, item in enumerate(items)}\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[1, 2])\n",
    "    \n",
    "    # --- Top Plot (Performance Curve) ---\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    \n",
    "    if sampling_method == 'AL':\n",
    "        sorted_original_indices = data_sorted['index'].values\n",
    "        intelligent_indices = list(set(all_sampled_indices) - set(burnin_indices))\n",
    "        colors_dots = ['darkgreen' if idx in intelligent_indices else 'darkgreen' if idx in burnin_indices else 'lightgreen' for idx in sorted_original_indices]\n",
    "        ax0.scatter(range(len(acc_sort)), acc_sort, c=colors_dots, s=10, alpha=0.5)\n",
    "    else:\n",
    "        ax0.plot(range(len(acc_sort)), acc_sort, marker='o', linestyle='None', markersize=2, color=\"black\")\n",
    "\n",
    "    ax0.axhline(y=0, color='blue', linestyle='dashed')\n",
    "    ax0.set_ylabel('R-square', fontsize=14)\n",
    "    ax0.set_title(f'Specification curve analysis', fontsize=16)\n",
    "    ax0.grid(True, alpha=0.4)\n",
    "    ax0.set_xlim(-1, len(acc_sort))\n",
    "\n",
    "    # --- Bottom Plot (Decision Heatmap) ---\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "    \n",
    "    # Define colors for each category\n",
    "    category_colors = {'bl_run': '#00008B', 'rf_run': '#DAA520', 'tw_run': '#006400', 'el_run': '#800080'}\n",
    "\n",
    "    # 3. Iterate through each pipeline (x-axis position) and plot its decisions\n",
    "    for i, (idx, pipeline) in enumerate(df_forks.iterrows()):\n",
    "        # For each pipeline, iterate through its decision choices\n",
    "        for col_name, decision in pipeline.items():\n",
    "            if col_name in category_colors:\n",
    "                # Find the y-position for this decision\n",
    "                y_pos = item_y_map[str(decision)]\n",
    "                # Get the color for this category\n",
    "                color = category_colors[col_name]\n",
    "                # Plot the single dot\n",
    "                ax1.scatter(i, y_pos, color=color, s=25, edgecolor='none')\n",
    "\n",
    "    ax1.set_yticks(range(len(items)))\n",
    "    ax1.set_yticklabels(items, fontsize=12)\n",
    "    ax1.set_ylabel('Decision Node in Pipeline', fontsize=14)\n",
    "    ax1.set_xlim(-1, len(acc_sort))\n",
    "    ax1.set_ylim(-1, len(items))\n",
    "    ax1.grid(True, alpha=0.5)\n",
    "    # Invert y-axis to have bl_run at the bottom\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_PATH / f'spec_curve_{dataset_name}_{sampling_method}_{num_items}.svg')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fde6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5d976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_analyses(Pipelines, embed_features, model_config, data_partitions, sample_sizes):\n",
    "    \"\"\"\n",
    "    Performs all computationally expensive analyses and saves the results to disk.\n",
    "    This includes exhaustive analysis, sampling, and performance evaluation on both\n",
    "    the Prediction and Lockbox datasets. The results are saved in a .pkl file\n",
    "    for each sample size, which can be loaded later for plotting.\n",
    "\n",
    "    Args:\n",
    "        Pipelines (pd.DataFrame): DataFrame with all possible pipeline configurations.\n",
    "        embed_features (np.ndarray): The 2D embedding of the feature space.\n",
    "        model_config (dict): Dictionary of pipeline configurations.\n",
    "        data_partitions (dict): Dictionary containing the 'Prediction' and 'Lockbox' data splits.\n",
    "        sample_sizes (list): A list of integers representing the different sample sizes to test.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*25 + \" RUNNING ALL ANALYSES \" + \"=\"*25)\n",
    "    \n",
    "    # Unpack data partitions\n",
    "    FeaturePrediction, YPrediction = data_partitions['Prediction']\n",
    "    FeatureLockbox, YLockbox = data_partitions['Lockbox']\n",
    "\n",
    "    # --- Exhaustive Analysis (Ground Truth) ---\n",
    "    PredictedAcc_Full_Prediction = run_exhaustive_analysis(\"Prediction\", FeaturePrediction, YPrediction, model_config)\n",
    "    PredictedAcc_Full_Lockbox = run_exhaustive_analysis(\"Lockbox\", FeatureLockbox, YLockbox, model_config)\n",
    "\n",
    "    for num_items in sample_sizes:\n",
    "        print(f\"\\n--- Running analysis for sample size: {num_items} ---\")\n",
    "\n",
    "        # --- Step 1: Select pipelines based on the 'Prediction' dataset ---\n",
    "        n_burnin, n_bayesopt = 25, num_items\n",
    "        kernel, optimizer, utility, _, _, pbounds, nbrs, seed = initialize_bo(embed_features, 10, n_burnin, n_bayesopt)\n",
    "        bad_iter, sel_indices, _ = run_bo(optimizer, utility, n_burnin, n_bayesopt, pbounds, nbrs, seed, embed_features, model_config, YPrediction, FeaturePrediction, verbose=False)\n",
    "        \n",
    "        good_indices_all = [idx for i, idx in enumerate(sel_indices) if bad_iter[i] == 0]\n",
    "        al_burnin_indices = [idx for i, idx in enumerate(sel_indices) if bad_iter[i] == 0 and i < n_burnin]\n",
    "        al_intelligent_indices = [idx for i, idx in enumerate(sel_indices) if bad_iter[i] == 0 and i >= n_burnin]\n",
    "        \n",
    "        random_indices = np.random.choice(range(len(Pipelines)), num_items, replace=False)\n",
    "        stratified_samples = create_stratified_samples(Pipelines, [num_items])\n",
    "        stratified_indices = stratified_samples[f'Sample_{num_items}'].index.values\n",
    "\n",
    "        # --- Step 2: Evaluate performance and get AL estimations for both datasets ---\n",
    "        \n",
    "        # Performance on Prediction set\n",
    "        al_estimated_pred, _ = optimizer._gp.predict(embed_features, return_std=True)\n",
    "        al_sampled_pred = evaluate_pipelines(good_indices_all, FeaturePrediction, YPrediction, model_config)\n",
    "        rand_pred = evaluate_pipelines(random_indices, FeaturePrediction, YPrediction, model_config)\n",
    "        stra_pred = evaluate_pipelines(stratified_indices, FeaturePrediction, YPrediction, model_config)\n",
    "        \n",
    "        # Performance on Lockbox set\n",
    "        al_sampled_lockbox = evaluate_pipelines(good_indices_all, FeatureLockbox, YLockbox, model_config)\n",
    "        rand_lockbox = evaluate_pipelines(random_indices, FeatureLockbox, YLockbox, model_config)\n",
    "        stra_lockbox = evaluate_pipelines(stratified_indices, FeatureLockbox, YLockbox, model_config)\n",
    "\n",
    "        # CORRECTED LOGIC: Re-train GP on Lockbox performance to get a true Lockbox estimation\n",
    "        print(\"Re-training Gaussian Process model on Lockbox data...\")\n",
    "        gp_lockbox = GaussianProcessRegressor(kernel=kernel, normalize_y=True, n_restarts_optimizer=10)\n",
    "        gp_lockbox.fit(embed_features[good_indices_all], al_sampled_lockbox)\n",
    "        al_estimated_lockbox, _ = gp_lockbox.predict(embed_features, return_std=True)\n",
    "\n",
    "        # --- Step 3: Save all results and indices to disk ---\n",
    "        results_to_save = {\n",
    "            'indices': {\n",
    "                'al': good_indices_all,\n",
    "                'al_burnin': al_burnin_indices,\n",
    "                'al_intelligent': al_intelligent_indices,\n",
    "                'rand': random_indices,\n",
    "                'stra': stratified_indices\n",
    "            },\n",
    "            'performance': {\n",
    "                'Prediction': {\n",
    "                    'Full': PredictedAcc_Full_Prediction, 'AL_estimated': al_estimated_pred,\n",
    "                    'AL_sampled': al_sampled_pred, 'Rand': rand_pred, 'Stra': stra_pred\n",
    "                },\n",
    "                'Lockbox': {\n",
    "                    'Full': PredictedAcc_Full_Lockbox, 'AL_estimated': al_estimated_lockbox,\n",
    "                    'AL_sampled': al_sampled_lockbox, 'Rand': rand_lockbox, 'Stra': stra_lockbox\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(OUTPUT_PATH / f'analysis_results_{num_items}.pkl', 'wb') as f:\n",
    "            pickle.dump(results_to_save, f)\n",
    "        print(f\"All analysis results for sample size {num_items} saved.\")\n",
    "\n",
    "\n",
    "def generate_all_visuals(Pipelines, embed_features, sample_sizes):\n",
    "    \"\"\"\n",
    "    Loads pre-computed analysis results from .pkl files and generates all plots \n",
    "    and statistical comparisons for each dataset and sample size.\n",
    "\n",
    "    Args:\n",
    "        Pipelines (pd.DataFrame): DataFrame with all possible pipeline configurations.\n",
    "        embed_features (np.ndarray): The 2D embedding of the feature space.\n",
    "        sample_sizes (list): A list of integers representing the different sample sizes to generate visuals for.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" GENERATING ALL VISUALS & COMPARISONS \" + \"=\"*20)\n",
    "\n",
    "    for num_items in sample_sizes:\n",
    "        print(f\"\\n--- Generating visuals for sample size: {num_items} ---\")\n",
    "        \n",
    "        # Load the saved results\n",
    "        try:\n",
    "            with open(OUTPUT_PATH / f'analysis_results_{num_items}.pkl', 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Could not find analysis_results_{num_items}.pkl. Please run the analysis first.\")\n",
    "            continue\n",
    "\n",
    "        indices = results['indices']\n",
    "        performance = results['performance']\n",
    "        \n",
    "        data_for_export = {}\n",
    "\n",
    "        for dataset_name in ['Prediction', 'Lockbox']:\n",
    "            print(f\"\\n--- Processing visuals for '{dataset_name}' dataset ---\")\n",
    "            \n",
    "            # Unpack performance data for the current dataset\n",
    "            full_perf = performance[dataset_name]['Full']\n",
    "            al_estimated_perf = performance[dataset_name]['AL_estimated']\n",
    "            al_sampled_perf = performance[dataset_name]['AL_sampled']\n",
    "            rand_perf = performance[dataset_name]['Rand']\n",
    "            stra_perf = performance[dataset_name]['Stra']\n",
    "\n",
    "            # --- Create full DataFrames for functions that need them ---\n",
    "            al_df = Pipelines.iloc[indices['al']].copy()\n",
    "            al_df['perf_pipelines'] = al_sampled_perf\n",
    "            \n",
    "            rand_df = Pipelines.iloc[indices['rand']].copy()\n",
    "            rand_df['perf_pipelines'] = rand_perf\n",
    "\n",
    "            stra_df = Pipelines.iloc[indices['stra']].copy()\n",
    "            stra_df['perf_pipelines'] = stra_perf\n",
    "            \n",
    "            full_df = Pipelines.copy()\n",
    "            full_df['perf_pipelines'] = full_perf\n",
    "\n",
    "            al_spec_df = Pipelines.copy()\n",
    "            al_spec_df['perf_pipelines'] = al_estimated_perf\n",
    "            \n",
    "            # --- Store data for final export ---\n",
    "            data_for_export[f'All_{dataset_name}'] = full_df\n",
    "            data_for_export[f'AL_{dataset_name}'] = al_spec_df\n",
    "            data_for_export[f'Rand_{dataset_name}'] = rand_df\n",
    "            data_for_export[f'Stra_{dataset_name}'] = stra_df\n",
    "\n",
    "            # --- KS Statistics ---\n",
    "            al_combined_perf = al_estimated_perf.copy()\n",
    "            al_combined_perf[indices['al']] = al_sampled_perf\n",
    "\n",
    "            ks_results = {\n",
    "                'Full': full_perf,\n",
    "                'Active Learning': al_combined_perf,\n",
    "                'Random': rand_perf,\n",
    "                'Stratified': stra_perf\n",
    "            }\n",
    "            ks_stats = {name: ks_2samp(full_perf, data) for name, data in ks_results.items()}\n",
    "            medians_df = pd.DataFrame({\n",
    "                'Sampling Method': list(ks_results.keys()),\n",
    "                'Median': [pd.Series(data).median() for data in ks_results.values()],\n",
    "                'KS Statistic': [s.statistic for s in ks_stats.values()],\n",
    "                'KS p-value': [s.pvalue for s in ks_stats.values()]\n",
    "            })\n",
    "            medians_df.to_csv(OUTPUT_PATH / f'medianAndKS_{dataset_name}_{num_items}.csv', index=False)\n",
    "            print(f\"\\nMedian and KS Statistics for '{dataset_name}':\\n{medians_df}\")\n",
    "\n",
    "            # --- Identifying best pipeline ---\n",
    "            identify_best_pipelines(dataset_name, num_items, Pipelines, full_perf, al_df, rand_df, stra_df)\n",
    "\n",
    "            # --- Plot raincloud plot ---\n",
    "            plot_raincloud(dataset_name, num_items, full_perf, al_estimated_perf, rand_df, stra_df, indices['al_burnin'], indices['al_intelligent'])\n",
    "\n",
    "            # --- Plot the sampled pipelines in space ---\n",
    "            plot_sampled_pipelines_in_space(dataset_name, num_items, embed_features, indices['al'], indices['rand'], indices['stra'])\n",
    "\n",
    "            # --- Measuring similarity ---\n",
    "            dist_al = average_nearest_neighbor_distance(embed_features[indices['al']], embed_features)\n",
    "            dist_rand = average_nearest_neighbor_distance(embed_features[indices['rand']], embed_features)\n",
    "            dist_stra = average_nearest_neighbor_distance(embed_features[indices['stra']], embed_features)\n",
    "            dist_df = pd.DataFrame({'Method': ['Active Learning', 'Random', 'Stratified'], 'Avg Nearest Neighbor Dist': [dist_al, dist_rand, dist_stra]})\n",
    "            dist_df.to_csv(OUTPUT_PATH / f'distances_{dataset_name}_{num_items}.csv', index=False)\n",
    "            \n",
    "            # --- Spec Curve Plots ---\n",
    "            spec_curve(al_spec_df, dataset_name, \"AL\", num_items, all_sampled_indices=indices['al'], burnin_indices=indices['al_burnin'])\n",
    "            spec_curve(rand_df, dataset_name, \"Rand\", num_items)\n",
    "            spec_curve(stra_df, dataset_name, \"Stra\", num_items)\n",
    "        \n",
    "        # --- Export all data to a single Excel file ---\n",
    "        export_all_data_to_excel(num_items, data_for_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ae68c",
   "metadata": {},
   "source": [
    "### 6. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b740f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data loading complete.\n",
      "Creating pipeline configurations...\n",
      "528 pipeline configurations created.\n",
      "Data partitioned: Prediction set=50, Lockbox set=28\n",
      "\n",
      "========================= RUNNING ALL ANALYSES =========================\n",
      "Starting exhaustive analysis for 'Prediction' dataset...\n",
      "Exhaustive analysis for 'Prediction' complete. Results saved.\n",
      "Starting exhaustive analysis for 'Lockbox' dataset...\n",
      "Exhaustive analysis for 'Lockbox' complete. Results saved.\n",
      "\n",
      "--- Running analysis for sample size: 26 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization: 100%|██████████| 51/51 [01:11<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-training Gaussian Process model on Lockbox data...\n",
      "All analysis results for sample size 26 saved.\n",
      "\n",
      "==================== GENERATING ALL VISUALS & COMPARISONS ====================\n",
      "\n",
      "--- Generating visuals for sample size: 26 ---\n",
      "\n",
      "--- Processing visuals for 'Prediction' dataset ---\n",
      "\n",
      "Median and KS Statistics for 'Prediction':\n",
      "   Sampling Method    Median  KS Statistic  KS p-value\n",
      "0             Full  0.084242      0.000000    1.000000\n",
      "1  Active Learning  0.076701      0.104167    0.006467\n",
      "2           Random  0.074911      0.134470    0.710119\n",
      "3       Stratified  0.087128      0.115676    0.855668\n",
      "Identifying best pipelines for 'Prediction'...\n",
      "Generating raincloud plot for 'Prediction'...\n",
      "Plotting sampled pipelines in space for 'Prediction'...\n",
      "Generating spec curve for Prediction - AL...\n",
      "Generating spec curve for Prediction - Rand...\n",
      "Generating spec curve for Prediction - Stra...\n",
      "\n",
      "--- Processing visuals for 'Lockbox' dataset ---\n",
      "\n",
      "Median and KS Statistics for 'Lockbox':\n",
      "   Sampling Method    Median  KS Statistic  KS p-value\n",
      "0             Full  0.137951      0.000000    1.000000\n",
      "1  Active Learning  0.152169      0.104167    0.006467\n",
      "2           Random  0.157186      0.106061    0.914398\n",
      "3       Stratified  0.110748      0.166521    0.447857\n",
      "Identifying best pipelines for 'Lockbox'...\n",
      "Generating raincloud plot for 'Lockbox'...\n",
      "Plotting sampled pipelines in space for 'Lockbox'...\n",
      "Generating spec curve for Lockbox - AL...\n",
      "Generating spec curve for Lockbox - Rand...\n",
      "Generating spec curve for Lockbox - Stra...\n",
      "\n",
      "Exporting all data to a single Excel file: c:\\Users\\danie\\Documents\\Projects\\EEG multiverse\\Scripts\\Revision\\Updated\\Output\\All_Results_Combined_26.xlsx\n",
      "Export complete.\n",
      "\n",
      "Workflow complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Set Up ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / 'Data'\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Flags to control execution ---\n",
    "RUN_ANALYSIS = True\n",
    "RUN_PLOTTING = True\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "features_sp, embed_features, Y_all = load_and_prepare_data(DATA_PATH)\n",
    "Pipelines, model_config = create_pipeline_configurations()\n",
    "\n",
    "n_spdefine, n_prediction, n_lockbox = 20, 50, 28\n",
    "remaining_indices = np.arange(n_spdefine, len(Y_all))\n",
    "rng = np.random.default_rng(15)\n",
    "rng.shuffle(remaining_indices)\n",
    "\n",
    "data_partitions = {\n",
    "    'Prediction': (features_sp[remaining_indices[:n_prediction], :, :], Y_all[remaining_indices[:n_prediction]]),\n",
    "    'Lockbox': (features_sp[remaining_indices[n_prediction:], :, :], Y_all[remaining_indices[n_prediction:]])\n",
    "}\n",
    "print(f\"Data partitioned: Prediction set={len(data_partitions['Prediction'][1])}, Lockbox set={len(data_partitions['Lockbox'][1])}\")\n",
    "\n",
    "# --- Run Analyses ---\n",
    "sample_sizes = [26]\n",
    "\n",
    "if RUN_ANALYSIS:\n",
    "    run_all_analyses(Pipelines, embed_features, model_config, data_partitions, sample_sizes)\n",
    "\n",
    "if RUN_PLOTTING:\n",
    "    generate_all_visuals(Pipelines, embed_features, sample_sizes)\n",
    "\n",
    "print(\"\\nWorkflow complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275c298",
   "metadata": {},
   "source": [
    "The following cells running supplementary analyses: VIF analysis for the regression model and visualizing specefication curve analysis for the full multiverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5f2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= RUNNING VIF ANALYSIS =========================\n",
      "\n",
      "Saved R-squared and VIF results to: c:\\Users\\danie\\Documents\\Projects\\EEG multiverse\\Scripts\\Revision\\Updated\\Output\\R2_and_VIF_results.csv\n",
      "Saved VIF distribution plot to: c:\\Users\\danie\\Documents\\Projects\\EEG multiverse\\Scripts\\Revision\\Updated\\Output\\VIF_distribution_plot.svg\n"
     ]
    }
   ],
   "source": [
    "RUN_VIF_ANALYSIS = True\n",
    "\n",
    "# --- Optional: Run VIF Analysis ---\n",
    "if RUN_VIF_ANALYSIS:\n",
    "    print(\"\\n\" + \"=\"*25 + \" RUNNING VIF ANALYSIS \" + \"=\"*25)\n",
    "    \n",
    "    # We will run this on the Prediction dataset\n",
    "    FeaturePrediction, YPrediction = data_partitions['Prediction']\n",
    "    \n",
    "    all_r2 = []\n",
    "    all_vifs = []\n",
    "    \n",
    "    # Loop through all pipelines and calculate R2 and VIF\n",
    "    for i in range(len(Pipelines)):\n",
    "        r2, vifs = objective_func_reg_IVF(i, YPrediction, model_config, FeaturePrediction)\n",
    "        all_r2.append(r2)\n",
    "        all_vifs.append(vifs)\n",
    "        \n",
    "    # Create the results DataFrame\n",
    "    vif_df = pd.DataFrame(all_vifs, columns=[f'VIF_Feature_{j+1}' for j in range(len(all_vifs[0]))])\n",
    "    r2_df = pd.DataFrame(all_r2, columns=['R_Squared'])\n",
    "    \n",
    "    # Combine pipeline specs with the results\n",
    "    final_results_df = pd.concat([Pipelines, r2_df, vif_df], axis=1)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_csv_path = OUTPUT_PATH / 'R2_and_VIF_results.csv'\n",
    "    final_results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nSaved R-squared and VIF results to: {output_csv_path}\")\n",
    "    \n",
    "    # Plot the distribution of VIF scores\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.boxplot(data=vif_df)\n",
    "    plt.title('Distribution of Variance Inflation Factor (VIF) for each Feature', fontsize=16)\n",
    "    plt.ylabel('VIF Value')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    output_plot_path = OUTPUT_PATH / 'VIF_distribution_plot.svg'\n",
    "    plt.savefig(output_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved VIF distribution plot to: {output_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b23bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating spec curve for the full multiverse...\n",
      "Generating spec curve for Prediction - Full...\n"
     ]
    }
   ],
   "source": [
    "results_filepath = OUTPUT_PATH / f'26_version2' / f'analysis_results_{26}.pkl'\n",
    "with open(results_filepath, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "\n",
    "# --- Step 2: Extract the full multiverse performance data ---\n",
    "# Get the performance array for all pipelines on the \"Prediction\" dataset\n",
    "full_multiverse_performance = results['performance']['Prediction']['Full']\n",
    "\n",
    "\n",
    "# --- Step 3: Create the DataFrame for the spec curve ---\n",
    "# This combines the pipeline specifications with their performance scores\n",
    "full_df = Pipelines.copy()\n",
    "full_df['perf_pipelines'] = full_multiverse_performance\n",
    "\n",
    "\n",
    "# --- Step 4: Generate and save the specification curve ---\n",
    "print(\"Generating spec curve for the full multiverse...\")\n",
    "spec_curve(full_df, \"Prediction\", \"Full\", len(Pipelines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samplingEEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
